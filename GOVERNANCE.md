# Governance Framework

## Who We Are

State of Algorithms is run by three founding editors based in Germany and The Netherlands. We operate as a collective, with all major editorial decisions requiring agreement from at least two editors.

## Why Pseudonymous?

We maintain verified pseudonymous identities for two reasons:

**Protection from harassment:** Nuanced AI discourse often attracts bad-faith attacks from both pro-AI and anti-AI extremes. Pseudonymity protects us from personal harassment while remaining fully accountable for our work.

**Focus on substance:** Our credibility comes from our work quality, transparent methods, and commitment to evidence - not from our personal credentials or institutional affiliations.

We have verified each other's qualifications and lack of major conflicts of interest. As we grow, we're committed to securing external verification from a trusted third party.

## How We Make Decisions

### Editorial Process
- All submissions reviewed by at least two editors
- Major content decisions require at least two editors to agree
- Disagreements resolved through discussion and evidence
- All decisions include written reasoning

### Transparency Commitments
- Published reasoning for declined submissions (when requested)
- Open appeals process for editorial decisions
- Regular correction and clarification policies
- Community feedback actively sought and considered

## Our Principles in Practice

### What We Won't Do
- Never claim neutrality - only transparency about our perspective
- Never dismiss concerns without substantive engagement
- Never platform known bad-faith actors regardless of "balance"
- Never allow external pressure to compromise our editorial standards

### What We Will Do
- Acknowledge uncertainty and limitations in our analysis
- Correct errors promptly and prominently
- Seek diverse perspectives, especially from affected communities
- Evolve our practices based on community feedback

## How We Plan to Evolve

### Next 6 Months
- Establish regular publishing rhythm
- Build relationships with diverse contributors
- Create systems for community feedback
- Document editorial decision patterns

### 6-18 Months
- Consider bringing on additional editors with complementary expertise
- Implement more structured community input mechanisms
- Explore external verification of our pseudonymous identities
- Assess need for more formal governance structures

### Long-term Vision
- Community input on major editorial direction
- Possible transition to broader editorial board
- Replication of our model by other independent platforms
- Sustained influence on quality of AI discourse

## Accountability

### To Contributors
- Respectful, constructive feedback on all submissions
- Transparent explanation of editorial decisions
- Fair treatment regardless of contributor background or perspective

### To Community
- Consistent application of editorial principles
- Openness to criticism and course correction
- Regular assessment of our own biases and blind spots

### To Mission
- Evidence-based analysis over narrative or ideology
- Intellectual humility about what we don't know
- Independence from commercial and political pressures

## Amendment Process

This framework can be updated based on:
- Community feedback and needs
- Lessons learned from editorial experience
- Changes in the broader AI discourse landscape

Major changes will be announced with reasoning and implemented after community input period.

## Contact

For questions about our governance, appeals of editorial decisions, or suggestions for improvement: contact@stateofalgorithms.org

---
*Last updated: August 9, 2025*
*Next review: February 2026*
